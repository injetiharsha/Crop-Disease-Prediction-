{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/injetiharsha/Crop-Disease-Prediction-/blob/main/Crop_Detection_Code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBu_OjCHml8u"
      },
      "source": [
        "### Import Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "RilxkK7Rml8x"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Restart Runtime\n",
        "#import os\n",
        "#os._exit(0)  # This will force restart the runtime\n"
      ],
      "metadata": {
        "id": "WwMwk7u_xnVC"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Reinstall the correct versions\n",
        "!pip install --upgrade sympy torchvision torch\n",
        "\n",
        "# Step 3: Import everything again (after installation)\n",
        "import torch\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Step 4: Check if everything works\n",
        "print(\"✅ Torch and torchvision loaded successfully!\")\n"
      ],
      "metadata": {
        "id": "53GSUpgUxpUl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb012c84-c39e-4767-a912-d6a58f705295"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (1.13.1)\n",
            "Collecting sympy\n",
            "  Downloading sympy-1.13.3-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m93.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m76.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m54.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m65.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n",
            "✅ Torch and torchvision loaded successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "dataset_zip_path = \"/Plant_leave_diseases_dataset_without_augmentation.zip\"\n",
        "\n",
        "# Check file type\n",
        "if os.path.exists(dataset_zip_path):\n",
        "    print(\"File exists! Checking type...\")\n",
        "    !file /content/dataset.zip\n",
        "else:\n",
        "    print(\"File does not exist!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "odHveMicyKII",
        "outputId": "206494e2-9882-4ef4-d141-e770401c1053"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File exists! Checking type...\n",
            "/content/dataset.zip: empty\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "BJangQ79ml8z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8b4e1a5-6f85-4949-9761-9333b1ec0384"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting dataset...\n",
            "Extracted files: ['.config', 'dataset.zip', 'Plant_leave_diseases_dataset_without_augmentation', 'sample_data']\n",
            "✅ Dataset loaded successfully!\n",
            "Total Images: 16223\n",
            "Classes: ['Background_without_leaves', 'Tomato___Bacterial_spot', 'Tomato___Early_blight', 'Tomato___Late_blight', 'Tomato___Leaf_Mold', 'Tomato___Septoria_leaf_spot', 'Tomato___Tomato_Yellow_Leaf_Curl_Virus', 'Tomato___Tomato_mosaic_virus', 'Tomato___healthy']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import zipfile\n",
        "from torchvision import transforms, datasets\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Define dataset zip file path\n",
        "dataset_zip_path = \"/Plant_leave_diseases_dataset_without_augmentation.zip\"\n",
        "\n",
        "# Extract dataset if not already extracted\n",
        "dataset_root = \"/content/Plant_leave_diseases_dataset_without_augmentation\"  # Check actual folder name\n",
        "\n",
        "if not os.path.exists(dataset_root):\n",
        "    print(\"Extracting dataset...\")\n",
        "    with zipfile.ZipFile(dataset_zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(\"/content/\")\n",
        "else:\n",
        "    print(\"Dataset already extracted. Skipping extraction.\")\n",
        "\n",
        "# Verify extracted files\n",
        "print(\"Extracted files:\", os.listdir(\"/content/\"))\n",
        "\n",
        "# Define the correct dataset path\n",
        "dataset_path = dataset_root  # Adjust if images are inside a subfolder\n",
        "\n",
        "if not os.path.exists(dataset_path):\n",
        "    raise FileNotFoundError(f\"Dataset folder not found at {dataset_path}. Check extracted files.\")\n",
        "\n",
        "# Define Transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # Resize images\n",
        "    transforms.ToTensor()           # Convert to tensor\n",
        "])\n",
        "\n",
        "# Load Dataset\n",
        "dataset = datasets.ImageFolder(root=dataset_path, transform=transform)\n",
        "\n",
        "# Verify Dataset Loaded\n",
        "print(\"✅ Dataset loaded successfully!\")\n",
        "print(f\"Total Images: {len(dataset)}\")\n",
        "print(f\"Classes: {dataset.classes}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4t2RuAbmml81"
      },
      "source": [
        "### Import Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "bwj4f75Tml82"
      },
      "outputs": [],
      "source": [
        "indices = list(range(len(dataset)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "IdMfnEBeml83"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "split = int(np.floor(0.85 * len(dataset)))  # train_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "2VRQqUf9ml83"
      },
      "outputs": [],
      "source": [
        "validation = int(np.floor(0.70 * split))  # validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "bIM-nvVbml84",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cdb82f84-a71a-4cad-e32f-9fec1d2045f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 9652 13789 16223\n"
          ]
        }
      ],
      "source": [
        "print(0, validation, split, len(dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "u6acbYavml84",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6f9ecb4-4c7f-4768-d209-d4481378b383"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "length of train size :9652\n",
            "length of validation size :4137\n",
            "length of test size :6571\n"
          ]
        }
      ],
      "source": [
        "print(f\"length of train size :{validation}\")\n",
        "print(f\"length of validation size :{split - validation}\")\n",
        "print(f\"length of test size :{len(dataset)-validation}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "XpuSFUPuml84"
      },
      "outputs": [],
      "source": [
        "np.random.shuffle(indices)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0y41PNltml84"
      },
      "source": [
        "### Split into Train and Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "_ttvgEcKml84"
      },
      "outputs": [],
      "source": [
        "train_indices, validation_indices, test_indices = (\n",
        "    indices[:validation],\n",
        "    indices[validation:split],\n",
        "    indices[split:],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Y0-NXLl0ml85"
      },
      "outputs": [],
      "source": [
        "train_sampler = SubsetRandomSampler(train_indices)\n",
        "validation_sampler = SubsetRandomSampler(validation_indices)\n",
        "test_sampler = SubsetRandomSampler(test_indices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "E9ccAIUHml85"
      },
      "outputs": [],
      "source": [
        "targets_size = len(dataset.class_to_idx)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ur9ZXyEWml86"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xAvU0QNFml86"
      },
      "source": [
        "<b>Convolution Aithmetic Equation : </b>(W - F + 2P) / S + 1 <br>\n",
        "W = Input Size<br>\n",
        "F = Filter Size<br>\n",
        "P = Padding Size<br>\n",
        "S = Stride <br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UIFbZKHVml86"
      },
      "source": [
        "### Transfer Learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y-gpRMu4ml86"
      },
      "outputs": [],
      "source": [
        "# model = models.vgg16(pretrained=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2N5B1N7Eml86"
      },
      "outputs": [],
      "source": [
        "# for params in model.parameters():\n",
        "#     params.requires_grad = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-n6c41dxml87"
      },
      "outputs": [],
      "source": [
        "# model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bdxqU9dyml87"
      },
      "outputs": [],
      "source": [
        "# n_features = model.classifier[0].in_features\n",
        "# n_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1kAp4__4ml87"
      },
      "outputs": [],
      "source": [
        "# model.classifier = nn.Sequential(\n",
        "#     nn.Linear(n_features, 1024),\n",
        "#     nn.ReLU(),\n",
        "#     nn.Dropout(0.4),\n",
        "#     nn.Linear(1024, targets_size),\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1VA43tSrml88"
      },
      "outputs": [],
      "source": [
        "# model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqBYkHTFml88"
      },
      "source": [
        "### Original Modeling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "GgQ7PBA5ml88"
      },
      "outputs": [],
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self, K):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv_layers = nn.Sequential(\n",
        "            # conv1\n",
        "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.MaxPool2d(2),\n",
        "            # conv2\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.MaxPool2d(2),\n",
        "            # conv3\n",
        "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.MaxPool2d(2),\n",
        "            # conv4\n",
        "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.MaxPool2d(2),\n",
        "        )\n",
        "\n",
        "        self.dense_layers = nn.Sequential(\n",
        "            nn.Dropout(0.4),\n",
        "            nn.Linear(50176, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.4),\n",
        "            nn.Linear(1024, 39),\n",
        "        )\n",
        "\n",
        "    def forward(self, X):\n",
        "        out = self.conv_layers(X)\n",
        "\n",
        "        # Flatten\n",
        "        out = out.view(-1, 50176)\n",
        "\n",
        "        # Fully connected\n",
        "        out = self.dense_layers(out)\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Xx7cWml7ml89",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06a78d94-fe0b-428d-88e2-4a1cc9ac862f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "f55JW2ssml89"
      },
      "outputs": [],
      "source": [
        "device = \"cuda\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "F4vHYuzHml89"
      },
      "outputs": [],
      "source": [
        "model = CNN(targets_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "DlNsKj3bml8-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee8935e3-77a0-447d-87d2-ccaa12c046ae"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNN(\n",
              "  (conv_layers): Sequential(\n",
              "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (4): ReLU()\n",
              "    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (7): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (8): ReLU()\n",
              "    (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (10): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU()\n",
              "    (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (14): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (15): ReLU()\n",
              "    (16): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (17): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (18): ReLU()\n",
              "    (19): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (20): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (21): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (22): ReLU()\n",
              "    (23): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (24): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (25): ReLU()\n",
              "    (26): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (dense_layers): Sequential(\n",
              "    (0): Dropout(p=0.4, inplace=False)\n",
              "    (1): Linear(in_features=50176, out_features=1024, bias=True)\n",
              "    (2): ReLU()\n",
              "    (3): Dropout(p=0.4, inplace=False)\n",
              "    (4): Linear(in_features=1024, out_features=39, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "fLreCjbiml8-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "607e8ede-dd61-4734-9d0c-7af6d37b6963"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.11/dist-packages (1.5.1)\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 32, 224, 224]             896\n",
            "              ReLU-2         [-1, 32, 224, 224]               0\n",
            "       BatchNorm2d-3         [-1, 32, 224, 224]              64\n",
            "            Conv2d-4         [-1, 32, 224, 224]           9,248\n",
            "              ReLU-5         [-1, 32, 224, 224]               0\n",
            "       BatchNorm2d-6         [-1, 32, 224, 224]              64\n",
            "         MaxPool2d-7         [-1, 32, 112, 112]               0\n",
            "            Conv2d-8         [-1, 64, 112, 112]          18,496\n",
            "              ReLU-9         [-1, 64, 112, 112]               0\n",
            "      BatchNorm2d-10         [-1, 64, 112, 112]             128\n",
            "           Conv2d-11         [-1, 64, 112, 112]          36,928\n",
            "             ReLU-12         [-1, 64, 112, 112]               0\n",
            "      BatchNorm2d-13         [-1, 64, 112, 112]             128\n",
            "        MaxPool2d-14           [-1, 64, 56, 56]               0\n",
            "           Conv2d-15          [-1, 128, 56, 56]          73,856\n",
            "             ReLU-16          [-1, 128, 56, 56]               0\n",
            "      BatchNorm2d-17          [-1, 128, 56, 56]             256\n",
            "           Conv2d-18          [-1, 128, 56, 56]         147,584\n",
            "             ReLU-19          [-1, 128, 56, 56]               0\n",
            "      BatchNorm2d-20          [-1, 128, 56, 56]             256\n",
            "        MaxPool2d-21          [-1, 128, 28, 28]               0\n",
            "           Conv2d-22          [-1, 256, 28, 28]         295,168\n",
            "             ReLU-23          [-1, 256, 28, 28]               0\n",
            "      BatchNorm2d-24          [-1, 256, 28, 28]             512\n",
            "           Conv2d-25          [-1, 256, 28, 28]         590,080\n",
            "             ReLU-26          [-1, 256, 28, 28]               0\n",
            "      BatchNorm2d-27          [-1, 256, 28, 28]             512\n",
            "        MaxPool2d-28          [-1, 256, 14, 14]               0\n",
            "          Dropout-29                [-1, 50176]               0\n",
            "           Linear-30                 [-1, 1024]      51,381,248\n",
            "             ReLU-31                 [-1, 1024]               0\n",
            "          Dropout-32                 [-1, 1024]               0\n",
            "           Linear-33                   [-1, 39]          39,975\n",
            "================================================================\n",
            "Total params: 52,595,399\n",
            "Trainable params: 52,595,399\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.57\n",
            "Forward/backward pass size (MB): 143.96\n",
            "Params size (MB): 200.64\n",
            "Estimated Total Size (MB): 345.17\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "!pip install torchsummary\n",
        "\n",
        "\n",
        "from torchsummary import summary\n",
        "\n",
        "summary(model, (3, 224, 224))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "B5knXNEgml8-"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()  # this include softmax + cross entropy loss\n",
        "optimizer = torch.optim.Adam(model.parameters())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "Wm9qkhP1ml8_"
      },
      "outputs": [],
      "source": [
        "device = \"cuda\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "kb8da08uml8_"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    dataset, batch_size=batch_size, sampler=train_sampler,pin_memory=True\n",
        ")\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    dataset, batch_size=batch_size, sampler=test_sampler\n",
        ")\n",
        "validation_loader = torch.utils.data.DataLoader(\n",
        "    dataset, batch_size=batch_size, sampler=validation_sampler\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CvQ0LW--ml8_"
      },
      "source": [
        "### Batch Gradient Descent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "JdJ98Mqfml8_"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "def calculate_f1(model, data_loader, device):\n",
        "    model.eval()  # Set model to evaluation mode\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in data_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)  # Get predicted class\n",
        "\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    return f1_score(all_labels, all_preds, average=\"weighted\")  # 'weighted' handles class imbalance\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "7Wwgh2rnml9K"
      },
      "outputs": [],
      "source": [
        "import datetime\n",
        "\n",
        "\n",
        "def batch_gd(model, criterion, train_loader, validation_loader, epochs):\n",
        "    train_losses = []  # Change from np.zeros() to a list\n",
        "    validation_losses = []\n",
        "    f1_scores = []  # Store F1 scores\n",
        "\n",
        "    for e in range(epochs):\n",
        "        t0 = datetime.now()\n",
        "        train_loss = []\n",
        "\n",
        "        # Training loop with progress bar\n",
        "        model.train()\n",
        "        for inputs, targets in tqdm(train_loader, desc=f\"Epoch {e+1}/{epochs}\"):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            output = model(inputs)\n",
        "            loss = criterion(output, targets)\n",
        "            train_loss.append(loss.item())\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        train_loss = np.mean(train_loss)\n",
        "        train_losses.append(train_loss)  # ✅ Store train loss\n",
        "\n",
        "        # Validation loop\n",
        "        model.eval()\n",
        "        validation_loss = []\n",
        "        for inputs, targets in validation_loader:\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            output = model(inputs)\n",
        "            loss = criterion(output, targets)\n",
        "            validation_loss.append(loss.item())\n",
        "\n",
        "        validation_loss = np.mean(validation_loss)\n",
        "        validation_losses.append(validation_loss)  # ✅ Store validation loss\n",
        "\n",
        "        # Calculate and store F1-score after each epoch\n",
        "        f1 = calculate_f1(model, validation_loader, device)\n",
        "        f1_scores.append(f1)\n",
        "\n",
        "        print(f\"Epoch {e+1}/{epochs} | Train Loss: {train_loss:.4f} | Val Loss: {validation_loss:.4f} | F1-Score: {f1:.4f} | Duration: {datetime.now() - t0}\")\n",
        "\n",
        "    return train_losses, validation_losses, f1_scores\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "5erWlfErml9L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "959a53da-5744-45f6-bfeb-ac05e712ca18"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current Time: 2025-04-03 17:54:12.356472\n",
            "|===========================================================================|\n",
            "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
            "|---------------------------------------------------------------------------|\n",
            "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
            "|===========================================================================|\n",
            "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocated memory      | 213789 KiB | 329259 KiB | 390842 KiB | 177053 KiB |\n",
            "|       from large pool | 212480 KiB | 324448 KiB | 383202 KiB | 170722 KiB |\n",
            "|       from small pool |   1309 KiB |   4811 KiB |   7640 KiB |   6331 KiB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active memory         | 213789 KiB | 329259 KiB | 390842 KiB | 177053 KiB |\n",
            "|       from large pool | 212480 KiB | 324448 KiB | 383202 KiB | 170722 KiB |\n",
            "|       from small pool |   1309 KiB |   4811 KiB |   7640 KiB |   6331 KiB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Requested memory      | 213778 KiB | 328214 KiB | 389283 KiB | 175505 KiB |\n",
            "|       from large pool | 212480 KiB | 323416 KiB | 381658 KiB | 169178 KiB |\n",
            "|       from small pool |   1298 KiB |   4798 KiB |   7625 KiB |   6327 KiB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved memory   | 331776 KiB | 331776 KiB | 331776 KiB |      0 B   |\n",
            "|       from large pool | 325632 KiB | 325632 KiB | 325632 KiB |      0 B   |\n",
            "|       from small pool |   6144 KiB |   6144 KiB |   6144 KiB |      0 B   |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable memory |  29923 KiB |  37832 KiB | 190344 KiB | 160421 KiB |\n",
            "|       from large pool |  29184 KiB |  35048 KiB | 180258 KiB | 151074 KiB |\n",
            "|       from small pool |    739 KiB |   2786 KiB |  10086 KiB |   9347 KiB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocations           |      61    |     109    |     127    |      66    |\n",
            "|       from large pool |       4    |      26    |      37    |      33    |\n",
            "|       from small pool |      57    |      83    |      90    |      33    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active allocs         |      61    |     109    |     127    |      66    |\n",
            "|       from large pool |       4    |      26    |      37    |      33    |\n",
            "|       from small pool |      57    |      83    |      90    |      33    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved segments |      11    |      11    |      11    |       0    |\n",
            "|       from large pool |       8    |       8    |       8    |       0    |\n",
            "|       from small pool |       3    |       3    |       3    |       0    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable allocs |       4    |      12    |      40    |      36    |\n",
            "|       from large pool |       3    |       8    |      24    |      21    |\n",
            "|       from small pool |       1    |       5    |      16    |      15    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
            "|===========================================================================|\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/10: 100%|██████████| 302/302 [00:55<00:00,  5.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10 | Train Loss: 2.2419 | Val Loss: 0.9233 | F1-Score: 0.7655 | Duration: 0:01:26.823616\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/10: 100%|██████████| 302/302 [00:55<00:00,  5.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/10 | Train Loss: 0.8653 | Val Loss: 0.7195 | F1-Score: 0.7739 | Duration: 0:01:26.587970\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/10: 100%|██████████| 302/302 [00:56<00:00,  5.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/10 | Train Loss: 0.7004 | Val Loss: 1.8197 | F1-Score: 0.6300 | Duration: 0:01:27.943487\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/10: 100%|██████████| 302/302 [00:56<00:00,  5.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/10 | Train Loss: 0.7010 | Val Loss: 194.2552 | F1-Score: 0.0725 | Duration: 0:01:28.392395\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/10: 100%|██████████| 302/302 [00:56<00:00,  5.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/10 | Train Loss: 0.7408 | Val Loss: 0.6523 | F1-Score: 0.8169 | Duration: 0:01:27.835835\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/10: 100%|██████████| 302/302 [00:56<00:00,  5.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/10 | Train Loss: 0.6121 | Val Loss: 1.8019 | F1-Score: 0.6428 | Duration: 0:01:28.651172\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/10: 100%|██████████| 302/302 [00:56<00:00,  5.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/10 | Train Loss: 0.5452 | Val Loss: 0.7639 | F1-Score: 0.8009 | Duration: 0:01:29.025262\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/10: 100%|██████████| 302/302 [00:57<00:00,  5.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/10 | Train Loss: 0.8553 | Val Loss: 1.6482 | F1-Score: 0.6854 | Duration: 0:01:28.594678\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/10: 100%|██████████| 302/302 [00:56<00:00,  5.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/10 | Train Loss: 0.6875 | Val Loss: 0.3855 | F1-Score: 0.8744 | Duration: 0:01:28.567984\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/10: 100%|██████████| 302/302 [00:56<00:00,  5.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/10 | Train Loss: 0.4726 | Val Loss: 0.4121 | F1-Score: 0.8830 | Duration: 0:01:29.301214\n"
          ]
        }
      ],
      "source": [
        "from datetime import datetime  # ✅ Import the class, not the module\n",
        "\n",
        "current_time = datetime.now()\n",
        "print(\"Current Time:\", current_time)\n",
        "\n",
        "print(torch.cuda.memory_summary(device=None, abbreviated=False))\n",
        "\n",
        "train_losses, validation_losses, f1_scores = batch_gd(model, criterion, train_loader, validation_loader, 10)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4obSO1y9ml9L"
      },
      "source": [
        "### Save the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "CGLCMfehml9L"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict() , 'plant_disease_model_14.pth')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XM3UJ3LWml9M"
      },
      "source": [
        "### Load Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download(\"plant_disease_model_14.pth\")  # Download the model to your local machine\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "mS9__wUFE9SL",
        "outputId": "0d8efd4f-e779-40e2-cbb7-bbfd83f6fd09"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_c6792bae-d3fb-45fc-a143-3ebc270da59b\", \"plant_disease_model_14.pth\", 210410338)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "D2JdGrR0ml9M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4a2292f-de57-433c-f9d6-db3ddc1a05c5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNN(\n",
              "  (conv_layers): Sequential(\n",
              "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (4): ReLU()\n",
              "    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (7): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (8): ReLU()\n",
              "    (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (10): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU()\n",
              "    (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (14): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (15): ReLU()\n",
              "    (16): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (17): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (18): ReLU()\n",
              "    (19): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (20): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (21): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (22): ReLU()\n",
              "    (23): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (24): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (25): ReLU()\n",
              "    (26): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (dense_layers): Sequential(\n",
              "    (0): Dropout(p=0.4, inplace=False)\n",
              "    (1): Linear(in_features=50176, out_features=1024, bias=True)\n",
              "    (2): ReLU()\n",
              "    (3): Dropout(p=0.4, inplace=False)\n",
              "    (4): Linear(in_features=1024, out_features=39, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "targets_size = 9\n",
        "model = CNN(targets_size)\n",
        "model.load_state_dict(torch.load(\"plant_disease_model_14.pth\"))  # Load weights\n",
        "model.to(device)  # Move to GPU if needed\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "CdX2wEc2ml9M"
      },
      "outputs": [],
      "source": [
        "%matplotlib notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3RRVB8Nml9M"
      },
      "source": [
        "### Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "RfCbsdLLml9M"
      },
      "outputs": [],
      "source": [
        "def accuracy(loader):\n",
        "    model.eval()  # Switch to evaluation mode\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            pred = outputs.argmax(dim=1)\n",
        "            correct += (pred == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "    model.train()  # Switch back to training mode\n",
        "    return correct / total\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "wPDm_gx6ml9M",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "0c7008f4-0d81-4526-886a-4026e9d4eccf"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-9d96dca56e74>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mtrain_accuracies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mvalidation_accuracies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mtest_accuracies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-35-e411b588c8f3>\u001b[0m in \u001b[0;36maccuracy\u001b[0;34m(loader)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mcorrect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    709\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    762\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m             \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m             \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m    352\u001b[0m             \u001b[0mPIL\u001b[0m \u001b[0mImage\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRescaled\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m         \"\"\"\n\u001b[0;32m--> 354\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mantialias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation, max_size, antialias)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Anti-alias option is always applied for PIL Image input. Argument antialias is ignored.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0mpil_interpolation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_modes_mapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF_pil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpil_interpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mF_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mantialias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mantialias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/transforms/_functional_pil.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Got inappropriate size arg: {size}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(self, size, resample, box, reducing_gap)\u001b[0m\n\u001b[1;32m   2354\u001b[0m                 )\n\u001b[1;32m   2355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2356\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2358\u001b[0m     def reduce(\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "train_accuracies = []\n",
        "validation_accuracies = []\n",
        "test_accuracies = []\n",
        "\n",
        "epochs = 10  # Define the number of epochs\n",
        "\n",
        "for e in range(epochs):\n",
        "    train_accuracies.append(accuracy(train_loader))\n",
        "    validation_accuracies.append(accuracy(validation_loader))\n",
        "    test_accuracies.append(accuracy(test_loader))\n",
        "\n",
        "print(\"Training Accuracies:\", train_accuracies)\n",
        "print(\"Validation Accuracies:\", validation_accuracies)\n",
        "print(\"Test Accuracies:\", test_accuracies)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "K-8YGqPrml9M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d612a1a7-49e3-4fd1-9f4a-51da966851d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy : [0.9067550766680481, 0.9067550766680481, 0.9067550766680481, 0.9067550766680481, 0.9067550766680481, 0.9067550766680481]\n",
            "Test Accuracy : [0.8915365653245686, 0.8915365653245686, 0.8915365653245686, 0.8915365653245686, 0.8915365653245686]\n",
            "Validation Accuracy : [0.8834904520183708, 0.8834904520183708, 0.8834904520183708, 0.8834904520183708, 0.8834904520183708]\n"
          ]
        }
      ],
      "source": [
        "print(\n",
        "    f\"Train Accuracy : {train_accuracies}\\nTest Accuracy : {test_accuracies}\\nValidation Accuracy : {validation_accuracies}\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Z84S8aHml9N"
      },
      "source": [
        "### Plot the loss"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute accuracy on trained model (No Retraining)\n",
        "print(\"Computing accuracies without retraining...\\n\")\n",
        "\n",
        "# Store accuracies\n",
        "train_acc_list = []\n",
        "val_acc_list = []\n",
        "test_acc_list = []\n",
        "\n",
        "# Calculate accuracies\n",
        "train_acc = accuracy(eval_train_loader)\n",
        "val_acc = accuracy(eval_validation_loader)\n",
        "test_acc = accuracy(eval_test_loader)\n",
        "\n",
        "# Append to lists\n",
        "train_acc_list.append(train_acc)\n",
        "val_acc_list.append(val_acc)\n",
        "test_acc_list.append(test_acc)\n",
        "\n",
        "# Print computed accuracy\n",
        "print(f\"Training Accuracy: {train_acc:.4f}\")\n",
        "print(f\"Validation Accuracy: {val_acc:.4f}\")\n",
        "print(f\"Test Accuracy: {test_acc:.4f}\")\n",
        "\n",
        "# Plot Accuracy Graph\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(range(1, len(train_acc_list) + 1), train_acc_list, label='Train Accuracy', marker='o', linestyle='dashed')\n",
        "plt.plot(range(1, len(val_acc_list) + 1), val_acc_list, label='Validation Accuracy', marker='s', linestyle='solid')\n",
        "plt.plot(range(1, len(test_acc_list) + 1), test_acc_list, label='Test Accuracy', marker='^', linestyle='solid')\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Accuracy vs. Epochs (After Training)\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "1aNtsu0iUaVN",
        "outputId": "cc4b577a-c294-4afd-8a98-98a8ee19634a"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computing accuracies without retraining...\n",
            "\n",
            "Training Accuracy: 0.9086\n",
            "Validation Accuracy: 0.8874\n",
            "Test Accuracy: 0.8989\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "/* Put everything inside the global mpl namespace */\n",
              "/* global mpl */\n",
              "window.mpl = {};\n",
              "\n",
              "mpl.get_websocket_type = function () {\n",
              "    if (typeof WebSocket !== 'undefined') {\n",
              "        return WebSocket;\n",
              "    } else if (typeof MozWebSocket !== 'undefined') {\n",
              "        return MozWebSocket;\n",
              "    } else {\n",
              "        alert(\n",
              "            'Your browser does not have WebSocket support. ' +\n",
              "                'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
              "                'Firefox 4 and 5 are also supported but you ' +\n",
              "                'have to enable WebSockets in about:config.'\n",
              "        );\n",
              "    }\n",
              "};\n",
              "\n",
              "mpl.figure = function (figure_id, websocket, ondownload, parent_element) {\n",
              "    this.id = figure_id;\n",
              "\n",
              "    this.ws = websocket;\n",
              "\n",
              "    this.supports_binary = this.ws.binaryType !== undefined;\n",
              "\n",
              "    if (!this.supports_binary) {\n",
              "        var warnings = document.getElementById('mpl-warnings');\n",
              "        if (warnings) {\n",
              "            warnings.style.display = 'block';\n",
              "            warnings.textContent =\n",
              "                'This browser does not support binary websocket messages. ' +\n",
              "                'Performance may be slow.';\n",
              "        }\n",
              "    }\n",
              "\n",
              "    this.imageObj = new Image();\n",
              "\n",
              "    this.context = undefined;\n",
              "    this.message = undefined;\n",
              "    this.canvas = undefined;\n",
              "    this.rubberband_canvas = undefined;\n",
              "    this.rubberband_context = undefined;\n",
              "    this.format_dropdown = undefined;\n",
              "\n",
              "    this.image_mode = 'full';\n",
              "\n",
              "    this.root = document.createElement('div');\n",
              "    this.root.setAttribute('style', 'display: inline-block');\n",
              "    this._root_extra_style(this.root);\n",
              "\n",
              "    parent_element.appendChild(this.root);\n",
              "\n",
              "    this._init_header(this);\n",
              "    this._init_canvas(this);\n",
              "    this._init_toolbar(this);\n",
              "\n",
              "    var fig = this;\n",
              "\n",
              "    this.waiting = false;\n",
              "\n",
              "    this.ws.onopen = function () {\n",
              "        fig.send_message('supports_binary', { value: fig.supports_binary });\n",
              "        fig.send_message('send_image_mode', {});\n",
              "        if (fig.ratio !== 1) {\n",
              "            fig.send_message('set_device_pixel_ratio', {\n",
              "                device_pixel_ratio: fig.ratio,\n",
              "            });\n",
              "        }\n",
              "        fig.send_message('refresh', {});\n",
              "    };\n",
              "\n",
              "    this.imageObj.onload = function () {\n",
              "        if (fig.image_mode === 'full') {\n",
              "            // Full images could contain transparency (where diff images\n",
              "            // almost always do), so we need to clear the canvas so that\n",
              "            // there is no ghosting.\n",
              "            fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
              "        }\n",
              "        fig.context.drawImage(fig.imageObj, 0, 0);\n",
              "    };\n",
              "\n",
              "    this.imageObj.onunload = function () {\n",
              "        fig.ws.close();\n",
              "    };\n",
              "\n",
              "    this.ws.onmessage = this._make_on_message_function(this);\n",
              "\n",
              "    this.ondownload = ondownload;\n",
              "};\n",
              "\n",
              "mpl.figure.prototype._init_header = function () {\n",
              "    var titlebar = document.createElement('div');\n",
              "    titlebar.classList =\n",
              "        'ui-dialog-titlebar ui-widget-header ui-corner-all ui-helper-clearfix';\n",
              "    var titletext = document.createElement('div');\n",
              "    titletext.classList = 'ui-dialog-title';\n",
              "    titletext.setAttribute(\n",
              "        'style',\n",
              "        'width: 100%; text-align: center; padding: 3px;'\n",
              "    );\n",
              "    titlebar.appendChild(titletext);\n",
              "    this.root.appendChild(titlebar);\n",
              "    this.header = titletext;\n",
              "};\n",
              "\n",
              "mpl.figure.prototype._canvas_extra_style = function (_canvas_div) {};\n",
              "\n",
              "mpl.figure.prototype._root_extra_style = function (_canvas_div) {};\n",
              "\n",
              "mpl.figure.prototype._init_canvas = function () {\n",
              "    var fig = this;\n",
              "\n",
              "    var canvas_div = (this.canvas_div = document.createElement('div'));\n",
              "    canvas_div.setAttribute('tabindex', '0');\n",
              "    canvas_div.setAttribute(\n",
              "        'style',\n",
              "        'border: 1px solid #ddd;' +\n",
              "            'box-sizing: content-box;' +\n",
              "            'clear: both;' +\n",
              "            'min-height: 1px;' +\n",
              "            'min-width: 1px;' +\n",
              "            'outline: 0;' +\n",
              "            'overflow: hidden;' +\n",
              "            'position: relative;' +\n",
              "            'resize: both;' +\n",
              "            'z-index: 2;'\n",
              "    );\n",
              "\n",
              "    function on_keyboard_event_closure(name) {\n",
              "        return function (event) {\n",
              "            return fig.key_event(event, name);\n",
              "        };\n",
              "    }\n",
              "\n",
              "    canvas_div.addEventListener(\n",
              "        'keydown',\n",
              "        on_keyboard_event_closure('key_press')\n",
              "    );\n",
              "    canvas_div.addEventListener(\n",
              "        'keyup',\n",
              "        on_keyboard_event_closure('key_release')\n",
              "    );\n",
              "\n",
              "    this._canvas_extra_style(canvas_div);\n",
              "    this.root.appendChild(canvas_div);\n",
              "\n",
              "    var canvas = (this.canvas = document.createElement('canvas'));\n",
              "    canvas.classList.add('mpl-canvas');\n",
              "    canvas.setAttribute(\n",
              "        'style',\n",
              "        'box-sizing: content-box;' +\n",
              "            'pointer-events: none;' +\n",
              "            'position: relative;' +\n",
              "            'z-index: 0;'\n",
              "    );\n",
              "\n",
              "    this.context = canvas.getContext('2d');\n",
              "\n",
              "    var backingStore =\n",
              "        this.context.backingStorePixelRatio ||\n",
              "        this.context.webkitBackingStorePixelRatio ||\n",
              "        this.context.mozBackingStorePixelRatio ||\n",
              "        this.context.msBackingStorePixelRatio ||\n",
              "        this.context.oBackingStorePixelRatio ||\n",
              "        this.context.backingStorePixelRatio ||\n",
              "        1;\n",
              "\n",
              "    this.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
              "\n",
              "    var rubberband_canvas = (this.rubberband_canvas = document.createElement(\n",
              "        'canvas'\n",
              "    ));\n",
              "    rubberband_canvas.setAttribute(\n",
              "        'style',\n",
              "        'box-sizing: content-box;' +\n",
              "            'left: 0;' +\n",
              "            'pointer-events: none;' +\n",
              "            'position: absolute;' +\n",
              "            'top: 0;' +\n",
              "            'z-index: 1;'\n",
              "    );\n",
              "\n",
              "    // Apply a ponyfill if ResizeObserver is not implemented by browser.\n",
              "    if (this.ResizeObserver === undefined) {\n",
              "        if (window.ResizeObserver !== undefined) {\n",
              "            this.ResizeObserver = window.ResizeObserver;\n",
              "        } else {\n",
              "            var obs = _JSXTOOLS_RESIZE_OBSERVER({});\n",
              "            this.ResizeObserver = obs.ResizeObserver;\n",
              "        }\n",
              "    }\n",
              "\n",
              "    this.resizeObserverInstance = new this.ResizeObserver(function (entries) {\n",
              "        // There's no need to resize if the WebSocket is not connected:\n",
              "        // - If it is still connecting, then we will get an initial resize from\n",
              "        //   Python once it connects.\n",
              "        // - If it has disconnected, then resizing will clear the canvas and\n",
              "        //   never get anything back to refill it, so better to not resize and\n",
              "        //   keep something visible.\n",
              "        if (fig.ws.readyState != 1) {\n",
              "            return;\n",
              "        }\n",
              "        var nentries = entries.length;\n",
              "        for (var i = 0; i < nentries; i++) {\n",
              "            var entry = entries[i];\n",
              "            var width, height;\n",
              "            if (entry.contentBoxSize) {\n",
              "                if (entry.contentBoxSize instanceof Array) {\n",
              "                    // Chrome 84 implements new version of spec.\n",
              "                    width = entry.contentBoxSize[0].inlineSize;\n",
              "                    height = entry.contentBoxSize[0].blockSize;\n",
              "                } else {\n",
              "                    // Firefox implements old version of spec.\n",
              "                    width = entry.contentBoxSize.inlineSize;\n",
              "                    height = entry.contentBoxSize.blockSize;\n",
              "                }\n",
              "            } else {\n",
              "                // Chrome <84 implements even older version of spec.\n",
              "                width = entry.contentRect.width;\n",
              "                height = entry.contentRect.height;\n",
              "            }\n",
              "\n",
              "            // Keep the size of the canvas and rubber band canvas in sync with\n",
              "            // the canvas container.\n",
              "            if (entry.devicePixelContentBoxSize) {\n",
              "                // Chrome 84 implements new version of spec.\n",
              "                canvas.setAttribute(\n",
              "                    'width',\n",
              "                    entry.devicePixelContentBoxSize[0].inlineSize\n",
              "                );\n",
              "                canvas.setAttribute(\n",
              "                    'height',\n",
              "                    entry.devicePixelContentBoxSize[0].blockSize\n",
              "                );\n",
              "            } else {\n",
              "                canvas.setAttribute('width', width * fig.ratio);\n",
              "                canvas.setAttribute('height', height * fig.ratio);\n",
              "            }\n",
              "            /* This rescales the canvas back to display pixels, so that it\n",
              "             * appears correct on HiDPI screens. */\n",
              "            canvas.style.width = width + 'px';\n",
              "            canvas.style.height = height + 'px';\n",
              "\n",
              "            rubberband_canvas.setAttribute('width', width);\n",
              "            rubberband_canvas.setAttribute('height', height);\n",
              "\n",
              "            // And update the size in Python. We ignore the initial 0/0 size\n",
              "            // that occurs as the element is placed into the DOM, which should\n",
              "            // otherwise not happen due to the minimum size styling.\n",
              "            if (width != 0 && height != 0) {\n",
              "                fig.request_resize(width, height);\n",
              "            }\n",
              "        }\n",
              "    });\n",
              "    this.resizeObserverInstance.observe(canvas_div);\n",
              "\n",
              "    function on_mouse_event_closure(name) {\n",
              "        /* User Agent sniffing is bad, but WebKit is busted:\n",
              "         * https://bugs.webkit.org/show_bug.cgi?id=144526\n",
              "         * https://bugs.webkit.org/show_bug.cgi?id=181818\n",
              "         * The worst that happens here is that they get an extra browser\n",
              "         * selection when dragging, if this check fails to catch them.\n",
              "         */\n",
              "        var UA = navigator.userAgent;\n",
              "        var isWebKit = /AppleWebKit/.test(UA) && !/Chrome/.test(UA);\n",
              "        if(isWebKit) {\n",
              "            return function (event) {\n",
              "                /* This prevents the web browser from automatically changing to\n",
              "                 * the text insertion cursor when the button is pressed. We\n",
              "                 * want to control all of the cursor setting manually through\n",
              "                 * the 'cursor' event from matplotlib */\n",
              "                event.preventDefault()\n",
              "                return fig.mouse_event(event, name);\n",
              "            };\n",
              "        } else {\n",
              "            return function (event) {\n",
              "                return fig.mouse_event(event, name);\n",
              "            };\n",
              "        }\n",
              "    }\n",
              "\n",
              "    canvas_div.addEventListener(\n",
              "        'mousedown',\n",
              "        on_mouse_event_closure('button_press')\n",
              "    );\n",
              "    canvas_div.addEventListener(\n",
              "        'mouseup',\n",
              "        on_mouse_event_closure('button_release')\n",
              "    );\n",
              "    canvas_div.addEventListener(\n",
              "        'dblclick',\n",
              "        on_mouse_event_closure('dblclick')\n",
              "    );\n",
              "    // Throttle sequential mouse events to 1 every 20ms.\n",
              "    canvas_div.addEventListener(\n",
              "        'mousemove',\n",
              "        on_mouse_event_closure('motion_notify')\n",
              "    );\n",
              "\n",
              "    canvas_div.addEventListener(\n",
              "        'mouseenter',\n",
              "        on_mouse_event_closure('figure_enter')\n",
              "    );\n",
              "    canvas_div.addEventListener(\n",
              "        'mouseleave',\n",
              "        on_mouse_event_closure('figure_leave')\n",
              "    );\n",
              "\n",
              "    canvas_div.addEventListener('wheel', function (event) {\n",
              "        if (event.deltaY < 0) {\n",
              "            event.step = 1;\n",
              "        } else {\n",
              "            event.step = -1;\n",
              "        }\n",
              "        on_mouse_event_closure('scroll')(event);\n",
              "    });\n",
              "\n",
              "    canvas_div.appendChild(canvas);\n",
              "    canvas_div.appendChild(rubberband_canvas);\n",
              "\n",
              "    this.rubberband_context = rubberband_canvas.getContext('2d');\n",
              "    this.rubberband_context.strokeStyle = '#000000';\n",
              "\n",
              "    this._resize_canvas = function (width, height, forward) {\n",
              "        if (forward) {\n",
              "            canvas_div.style.width = width + 'px';\n",
              "            canvas_div.style.height = height + 'px';\n",
              "        }\n",
              "    };\n",
              "\n",
              "    // Disable right mouse context menu.\n",
              "    canvas_div.addEventListener('contextmenu', function (_e) {\n",
              "        event.preventDefault();\n",
              "        return false;\n",
              "    });\n",
              "\n",
              "    function set_focus() {\n",
              "        canvas.focus();\n",
              "        canvas_div.focus();\n",
              "    }\n",
              "\n",
              "    window.setTimeout(set_focus, 100);\n",
              "};\n",
              "\n",
              "mpl.figure.prototype._init_toolbar = function () {\n",
              "    var fig = this;\n",
              "\n",
              "    var toolbar = document.createElement('div');\n",
              "    toolbar.classList = 'mpl-toolbar';\n",
              "    this.root.appendChild(toolbar);\n",
              "\n",
              "    function on_click_closure(name) {\n",
              "        return function (_event) {\n",
              "            return fig.toolbar_button_onclick(name);\n",
              "        };\n",
              "    }\n",
              "\n",
              "    function on_mouseover_closure(tooltip) {\n",
              "        return function (event) {\n",
              "            if (!event.currentTarget.disabled) {\n",
              "                return fig.toolbar_button_onmouseover(tooltip);\n",
              "            }\n",
              "        };\n",
              "    }\n",
              "\n",
              "    fig.buttons = {};\n",
              "    var buttonGroup = document.createElement('div');\n",
              "    buttonGroup.classList = 'mpl-button-group';\n",
              "    for (var toolbar_ind in mpl.toolbar_items) {\n",
              "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
              "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
              "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
              "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
              "\n",
              "        if (!name) {\n",
              "            /* Instead of a spacer, we start a new button group. */\n",
              "            if (buttonGroup.hasChildNodes()) {\n",
              "                toolbar.appendChild(buttonGroup);\n",
              "            }\n",
              "            buttonGroup = document.createElement('div');\n",
              "            buttonGroup.classList = 'mpl-button-group';\n",
              "            continue;\n",
              "        }\n",
              "\n",
              "        var button = (fig.buttons[name] = document.createElement('button'));\n",
              "        button.classList = 'mpl-widget';\n",
              "        button.setAttribute('role', 'button');\n",
              "        button.setAttribute('aria-disabled', 'false');\n",
              "        button.addEventListener('click', on_click_closure(method_name));\n",
              "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
              "\n",
              "        var icon_img = document.createElement('img');\n",
              "        icon_img.src = '_images/' + image + '.png';\n",
              "        icon_img.srcset = '_images/' + image + '_large.png 2x';\n",
              "        icon_img.alt = tooltip;\n",
              "        button.appendChild(icon_img);\n",
              "\n",
              "        buttonGroup.appendChild(button);\n",
              "    }\n",
              "\n",
              "    if (buttonGroup.hasChildNodes()) {\n",
              "        toolbar.appendChild(buttonGroup);\n",
              "    }\n",
              "\n",
              "    var fmt_picker = document.createElement('select');\n",
              "    fmt_picker.classList = 'mpl-widget';\n",
              "    toolbar.appendChild(fmt_picker);\n",
              "    this.format_dropdown = fmt_picker;\n",
              "\n",
              "    for (var ind in mpl.extensions) {\n",
              "        var fmt = mpl.extensions[ind];\n",
              "        var option = document.createElement('option');\n",
              "        option.selected = fmt === mpl.default_extension;\n",
              "        option.innerHTML = fmt;\n",
              "        fmt_picker.appendChild(option);\n",
              "    }\n",
              "\n",
              "    var status_bar = document.createElement('span');\n",
              "    status_bar.classList = 'mpl-message';\n",
              "    toolbar.appendChild(status_bar);\n",
              "    this.message = status_bar;\n",
              "};\n",
              "\n",
              "mpl.figure.prototype.request_resize = function (x_pixels, y_pixels) {\n",
              "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
              "    // which will in turn request a refresh of the image.\n",
              "    this.send_message('resize', { width: x_pixels, height: y_pixels });\n",
              "};\n",
              "\n",
              "mpl.figure.prototype.send_message = function (type, properties) {\n",
              "    properties['type'] = type;\n",
              "    properties['figure_id'] = this.id;\n",
              "    this.ws.send(JSON.stringify(properties));\n",
              "};\n",
              "\n",
              "mpl.figure.prototype.send_draw_message = function () {\n",
              "    if (!this.waiting) {\n",
              "        this.waiting = true;\n",
              "        this.ws.send(JSON.stringify({ type: 'draw', figure_id: this.id }));\n",
              "    }\n",
              "};\n",
              "\n",
              "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
              "    var format_dropdown = fig.format_dropdown;\n",
              "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
              "    fig.ondownload(fig, format);\n",
              "};\n",
              "\n",
              "mpl.figure.prototype.handle_resize = function (fig, msg) {\n",
              "    var size = msg['size'];\n",
              "    if (size[0] !== fig.canvas.width || size[1] !== fig.canvas.height) {\n",
              "        fig._resize_canvas(size[0], size[1], msg['forward']);\n",
              "        fig.send_message('refresh', {});\n",
              "    }\n",
              "};\n",
              "\n",
              "mpl.figure.prototype.handle_rubberband = function (fig, msg) {\n",
              "    var x0 = msg['x0'] / fig.ratio;\n",
              "    var y0 = (fig.canvas.height - msg['y0']) / fig.ratio;\n",
              "    var x1 = msg['x1'] / fig.ratio;\n",
              "    var y1 = (fig.canvas.height - msg['y1']) / fig.ratio;\n",
              "    x0 = Math.floor(x0) + 0.5;\n",
              "    y0 = Math.floor(y0) + 0.5;\n",
              "    x1 = Math.floor(x1) + 0.5;\n",
              "    y1 = Math.floor(y1) + 0.5;\n",
              "    var min_x = Math.min(x0, x1);\n",
              "    var min_y = Math.min(y0, y1);\n",
              "    var width = Math.abs(x1 - x0);\n",
              "    var height = Math.abs(y1 - y0);\n",
              "\n",
              "    fig.rubberband_context.clearRect(\n",
              "        0,\n",
              "        0,\n",
              "        fig.canvas.width / fig.ratio,\n",
              "        fig.canvas.height / fig.ratio\n",
              "    );\n",
              "\n",
              "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
              "};\n",
              "\n",
              "mpl.figure.prototype.handle_figure_label = function (fig, msg) {\n",
              "    // Updates the figure title.\n",
              "    fig.header.textContent = msg['label'];\n",
              "};\n",
              "\n",
              "mpl.figure.prototype.handle_cursor = function (fig, msg) {\n",
              "    fig.canvas_div.style.cursor = msg['cursor'];\n",
              "};\n",
              "\n",
              "mpl.figure.prototype.handle_message = function (fig, msg) {\n",
              "    fig.message.textContent = msg['message'];\n",
              "};\n",
              "\n",
              "mpl.figure.prototype.handle_draw = function (fig, _msg) {\n",
              "    // Request the server to send over a new figure.\n",
              "    fig.send_draw_message();\n",
              "};\n",
              "\n",
              "mpl.figure.prototype.handle_image_mode = function (fig, msg) {\n",
              "    fig.image_mode = msg['mode'];\n",
              "};\n",
              "\n",
              "mpl.figure.prototype.handle_history_buttons = function (fig, msg) {\n",
              "    for (var key in msg) {\n",
              "        if (!(key in fig.buttons)) {\n",
              "            continue;\n",
              "        }\n",
              "        fig.buttons[key].disabled = !msg[key];\n",
              "        fig.buttons[key].setAttribute('aria-disabled', !msg[key]);\n",
              "    }\n",
              "};\n",
              "\n",
              "mpl.figure.prototype.handle_navigate_mode = function (fig, msg) {\n",
              "    if (msg['mode'] === 'PAN') {\n",
              "        fig.buttons['Pan'].classList.add('active');\n",
              "        fig.buttons['Zoom'].classList.remove('active');\n",
              "    } else if (msg['mode'] === 'ZOOM') {\n",
              "        fig.buttons['Pan'].classList.remove('active');\n",
              "        fig.buttons['Zoom'].classList.add('active');\n",
              "    } else {\n",
              "        fig.buttons['Pan'].classList.remove('active');\n",
              "        fig.buttons['Zoom'].classList.remove('active');\n",
              "    }\n",
              "};\n",
              "\n",
              "mpl.figure.prototype.updated_canvas_event = function () {\n",
              "    // Called whenever the canvas gets updated.\n",
              "    this.send_message('ack', {});\n",
              "};\n",
              "\n",
              "// A function to construct a web socket function for onmessage handling.\n",
              "// Called in the figure constructor.\n",
              "mpl.figure.prototype._make_on_message_function = function (fig) {\n",
              "    return function socket_on_message(evt) {\n",
              "        if (evt.data instanceof Blob) {\n",
              "            var img = evt.data;\n",
              "            if (img.type !== 'image/png') {\n",
              "                /* FIXME: We get \"Resource interpreted as Image but\n",
              "                 * transferred with MIME type text/plain:\" errors on\n",
              "                 * Chrome.  But how to set the MIME type?  It doesn't seem\n",
              "                 * to be part of the websocket stream */\n",
              "                img.type = 'image/png';\n",
              "            }\n",
              "\n",
              "            /* Free the memory for the previous frames */\n",
              "            if (fig.imageObj.src) {\n",
              "                (window.URL || window.webkitURL).revokeObjectURL(\n",
              "                    fig.imageObj.src\n",
              "                );\n",
              "            }\n",
              "\n",
              "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
              "                img\n",
              "            );\n",
              "            fig.updated_canvas_event();\n",
              "            fig.waiting = false;\n",
              "            return;\n",
              "        } else if (\n",
              "            typeof evt.data === 'string' &&\n",
              "            evt.data.slice(0, 21) === 'data:image/png;base64'\n",
              "        ) {\n",
              "            fig.imageObj.src = evt.data;\n",
              "            fig.updated_canvas_event();\n",
              "            fig.waiting = false;\n",
              "            return;\n",
              "        }\n",
              "\n",
              "        var msg = JSON.parse(evt.data);\n",
              "        var msg_type = msg['type'];\n",
              "\n",
              "        // Call the  \"handle_{type}\" callback, which takes\n",
              "        // the figure and JSON message as its only arguments.\n",
              "        try {\n",
              "            var callback = fig['handle_' + msg_type];\n",
              "        } catch (e) {\n",
              "            console.log(\n",
              "                \"No handler for the '\" + msg_type + \"' message type: \",\n",
              "                msg\n",
              "            );\n",
              "            return;\n",
              "        }\n",
              "\n",
              "        if (callback) {\n",
              "            try {\n",
              "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
              "                callback(fig, msg);\n",
              "            } catch (e) {\n",
              "                console.log(\n",
              "                    \"Exception inside the 'handler_\" + msg_type + \"' callback:\",\n",
              "                    e,\n",
              "                    e.stack,\n",
              "                    msg\n",
              "                );\n",
              "            }\n",
              "        }\n",
              "    };\n",
              "};\n",
              "\n",
              "function getModifiers(event) {\n",
              "    var mods = [];\n",
              "    if (event.ctrlKey) {\n",
              "        mods.push('ctrl');\n",
              "    }\n",
              "    if (event.altKey) {\n",
              "        mods.push('alt');\n",
              "    }\n",
              "    if (event.shiftKey) {\n",
              "        mods.push('shift');\n",
              "    }\n",
              "    if (event.metaKey) {\n",
              "        mods.push('meta');\n",
              "    }\n",
              "    return mods;\n",
              "}\n",
              "\n",
              "/*\n",
              " * return a copy of an object with only non-object keys\n",
              " * we need this to avoid circular references\n",
              " * https://stackoverflow.com/a/24161582/3208463\n",
              " */\n",
              "function simpleKeys(original) {\n",
              "    return Object.keys(original).reduce(function (obj, key) {\n",
              "        if (typeof original[key] !== 'object') {\n",
              "            obj[key] = original[key];\n",
              "        }\n",
              "        return obj;\n",
              "    }, {});\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.mouse_event = function (event, name) {\n",
              "    if (name === 'button_press') {\n",
              "        this.canvas.focus();\n",
              "        this.canvas_div.focus();\n",
              "    }\n",
              "\n",
              "    // from https://stackoverflow.com/q/1114465\n",
              "    var boundingRect = this.canvas.getBoundingClientRect();\n",
              "    var x = (event.clientX - boundingRect.left) * this.ratio;\n",
              "    var y = (event.clientY - boundingRect.top) * this.ratio;\n",
              "\n",
              "    this.send_message(name, {\n",
              "        x: x,\n",
              "        y: y,\n",
              "        button: event.button,\n",
              "        step: event.step,\n",
              "        buttons: event.buttons,\n",
              "        modifiers: getModifiers(event),\n",
              "        guiEvent: simpleKeys(event),\n",
              "    });\n",
              "\n",
              "    return false;\n",
              "};\n",
              "\n",
              "mpl.figure.prototype._key_event_extra = function (_event, _name) {\n",
              "    // Handle any extra behaviour associated with a key event\n",
              "};\n",
              "\n",
              "mpl.figure.prototype.key_event = function (event, name) {\n",
              "    // Prevent repeat events\n",
              "    if (name === 'key_press') {\n",
              "        if (event.key === this._key) {\n",
              "            return;\n",
              "        } else {\n",
              "            this._key = event.key;\n",
              "        }\n",
              "    }\n",
              "    if (name === 'key_release') {\n",
              "        this._key = null;\n",
              "    }\n",
              "\n",
              "    var value = '';\n",
              "    if (event.ctrlKey && event.key !== 'Control') {\n",
              "        value += 'ctrl+';\n",
              "    }\n",
              "    else if (event.altKey && event.key !== 'Alt') {\n",
              "        value += 'alt+';\n",
              "    }\n",
              "    else if (event.shiftKey && event.key !== 'Shift') {\n",
              "        value += 'shift+';\n",
              "    }\n",
              "\n",
              "    value += 'k' + event.key;\n",
              "\n",
              "    this._key_event_extra(event, name);\n",
              "\n",
              "    this.send_message(name, { key: value, guiEvent: simpleKeys(event) });\n",
              "    return false;\n",
              "};\n",
              "\n",
              "mpl.figure.prototype.toolbar_button_onclick = function (name) {\n",
              "    if (name === 'download') {\n",
              "        this.handle_save(this, null);\n",
              "    } else {\n",
              "        this.send_message('toolbar_button', { name: name });\n",
              "    }\n",
              "};\n",
              "\n",
              "mpl.figure.prototype.toolbar_button_onmouseover = function (tooltip) {\n",
              "    this.message.textContent = tooltip;\n",
              "};\n",
              "\n",
              "///////////////// REMAINING CONTENT GENERATED BY embed_js.py /////////////////\n",
              "// prettier-ignore\n",
              "var _JSXTOOLS_RESIZE_OBSERVER=function(A){var t,i=new WeakMap,n=new WeakMap,a=new WeakMap,r=new WeakMap,o=new Set;function s(e){if(!(this instanceof s))throw new TypeError(\"Constructor requires 'new' operator\");i.set(this,e)}function h(){throw new TypeError(\"Function is not a constructor\")}function c(e,t,i,n){e=0 in arguments?Number(arguments[0]):0,t=1 in arguments?Number(arguments[1]):0,i=2 in arguments?Number(arguments[2]):0,n=3 in arguments?Number(arguments[3]):0,this.right=(this.x=this.left=e)+(this.width=i),this.bottom=(this.y=this.top=t)+(this.height=n),Object.freeze(this)}function d(){t=requestAnimationFrame(d);var s=new WeakMap,p=new Set;o.forEach((function(t){r.get(t).forEach((function(i){var r=t instanceof window.SVGElement,o=a.get(t),d=r?0:parseFloat(o.paddingTop),f=r?0:parseFloat(o.paddingRight),l=r?0:parseFloat(o.paddingBottom),u=r?0:parseFloat(o.paddingLeft),g=r?0:parseFloat(o.borderTopWidth),m=r?0:parseFloat(o.borderRightWidth),w=r?0:parseFloat(o.borderBottomWidth),b=u+f,F=d+l,v=(r?0:parseFloat(o.borderLeftWidth))+m,W=g+w,y=r?0:t.offsetHeight-W-t.clientHeight,E=r?0:t.offsetWidth-v-t.clientWidth,R=b+v,z=F+W,M=r?t.width:parseFloat(o.width)-R-E,O=r?t.height:parseFloat(o.height)-z-y;if(n.has(t)){var k=n.get(t);if(k[0]===M&&k[1]===O)return}n.set(t,[M,O]);var S=Object.create(h.prototype);S.target=t,S.contentRect=new c(u,d,M,O),s.has(i)||(s.set(i,[]),p.add(i)),s.get(i).push(S)}))})),p.forEach((function(e){i.get(e).call(e,s.get(e),e)}))}return s.prototype.observe=function(i){if(i instanceof window.Element){r.has(i)||(r.set(i,new Set),o.add(i),a.set(i,window.getComputedStyle(i)));var n=r.get(i);n.has(this)||n.add(this),cancelAnimationFrame(t),t=requestAnimationFrame(d)}},s.prototype.unobserve=function(i){if(i instanceof window.Element&&r.has(i)){var n=r.get(i);n.has(this)&&(n.delete(this),n.size||(r.delete(i),o.delete(i))),n.size||r.delete(i),o.size||cancelAnimationFrame(t)}},A.DOMRectReadOnly=c,A.ResizeObserver=s,A.ResizeObserverEntry=h,A}; // eslint-disable-line\n",
              "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Left button pans, Right button zooms\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-arrows\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\\nx/y fixes axis\", \"fa fa-square-o\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o\", \"download\"]];\n",
              "\n",
              "mpl.extensions = [\"eps\", \"jpeg\", \"pgf\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\", \"webp\"];\n",
              "\n",
              "mpl.default_extension = \"png\";/* global mpl */\n",
              "\n",
              "var comm_websocket_adapter = function (comm) {\n",
              "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
              "    // object with the appropriate methods. Currently this is a non binary\n",
              "    // socket, so there is still some room for performance tuning.\n",
              "    var ws = {};\n",
              "\n",
              "    ws.binaryType = comm.kernel.ws.binaryType;\n",
              "    ws.readyState = comm.kernel.ws.readyState;\n",
              "    function updateReadyState(_event) {\n",
              "        if (comm.kernel.ws) {\n",
              "            ws.readyState = comm.kernel.ws.readyState;\n",
              "        } else {\n",
              "            ws.readyState = 3; // Closed state.\n",
              "        }\n",
              "    }\n",
              "    comm.kernel.ws.addEventListener('open', updateReadyState);\n",
              "    comm.kernel.ws.addEventListener('close', updateReadyState);\n",
              "    comm.kernel.ws.addEventListener('error', updateReadyState);\n",
              "\n",
              "    ws.close = function () {\n",
              "        comm.close();\n",
              "    };\n",
              "    ws.send = function (m) {\n",
              "        //console.log('sending', m);\n",
              "        comm.send(m);\n",
              "    };\n",
              "    // Register the callback with on_msg.\n",
              "    comm.on_msg(function (msg) {\n",
              "        //console.log('receiving', msg['content']['data'], msg);\n",
              "        var data = msg['content']['data'];\n",
              "        if (data['blob'] !== undefined) {\n",
              "            data = {\n",
              "                data: new Blob(msg['buffers'], { type: data['blob'] }),\n",
              "            };\n",
              "        }\n",
              "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
              "        ws.onmessage(data);\n",
              "    });\n",
              "    return ws;\n",
              "};\n",
              "\n",
              "mpl.mpl_figure_comm = function (comm, msg) {\n",
              "    // This is the function which gets called when the mpl process\n",
              "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
              "\n",
              "    var id = msg.content.data.id;\n",
              "    // Get hold of the div created by the display call when the Comm\n",
              "    // socket was opened in Python.\n",
              "    var element = document.getElementById(id);\n",
              "    var ws_proxy = comm_websocket_adapter(comm);\n",
              "\n",
              "    function ondownload(figure, _format) {\n",
              "        window.open(figure.canvas.toDataURL());\n",
              "    }\n",
              "\n",
              "    var fig = new mpl.figure(id, ws_proxy, ondownload, element);\n",
              "\n",
              "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
              "    // web socket which is closed, not our websocket->open comm proxy.\n",
              "    ws_proxy.onopen();\n",
              "\n",
              "    fig.parent_element = element;\n",
              "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
              "    if (!fig.cell_info) {\n",
              "        console.error('Failed to find cell for figure', id, fig);\n",
              "        return;\n",
              "    }\n",
              "    fig.cell_info[0].output_area.element.on(\n",
              "        'cleared',\n",
              "        { fig: fig },\n",
              "        fig._remove_fig_handler\n",
              "    );\n",
              "};\n",
              "\n",
              "mpl.figure.prototype.handle_close = function (fig, msg) {\n",
              "    var width = fig.canvas.width / fig.ratio;\n",
              "    fig.cell_info[0].output_area.element.off(\n",
              "        'cleared',\n",
              "        fig._remove_fig_handler\n",
              "    );\n",
              "    fig.resizeObserverInstance.unobserve(fig.canvas_div);\n",
              "\n",
              "    // Update the output cell to use the data from the current canvas.\n",
              "    fig.push_to_output();\n",
              "    var dataURL = fig.canvas.toDataURL();\n",
              "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
              "    // the notebook keyboard shortcuts fail.\n",
              "    IPython.keyboard_manager.enable();\n",
              "    fig.parent_element.innerHTML =\n",
              "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
              "    fig.close_ws(fig, msg);\n",
              "};\n",
              "\n",
              "mpl.figure.prototype.close_ws = function (fig, msg) {\n",
              "    fig.send_message('closing', msg);\n",
              "    // fig.ws.close()\n",
              "};\n",
              "\n",
              "mpl.figure.prototype.push_to_output = function (_remove_interactive) {\n",
              "    // Turn the data on the canvas into data in the output cell.\n",
              "    var width = this.canvas.width / this.ratio;\n",
              "    var dataURL = this.canvas.toDataURL();\n",
              "    this.cell_info[1]['text/html'] =\n",
              "        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
              "};\n",
              "\n",
              "mpl.figure.prototype.updated_canvas_event = function () {\n",
              "    // Tell IPython that the notebook contents must change.\n",
              "    IPython.notebook.set_dirty(true);\n",
              "    this.send_message('ack', {});\n",
              "    var fig = this;\n",
              "    // Wait a second, then push the new image to the DOM so\n",
              "    // that it is saved nicely (might be nice to debounce this).\n",
              "    setTimeout(function () {\n",
              "        fig.push_to_output();\n",
              "    }, 1000);\n",
              "};\n",
              "\n",
              "mpl.figure.prototype._init_toolbar = function () {\n",
              "    var fig = this;\n",
              "\n",
              "    var toolbar = document.createElement('div');\n",
              "    toolbar.classList = 'btn-toolbar';\n",
              "    this.root.appendChild(toolbar);\n",
              "\n",
              "    function on_click_closure(name) {\n",
              "        return function (_event) {\n",
              "            return fig.toolbar_button_onclick(name);\n",
              "        };\n",
              "    }\n",
              "\n",
              "    function on_mouseover_closure(tooltip) {\n",
              "        return function (event) {\n",
              "            if (!event.currentTarget.disabled) {\n",
              "                return fig.toolbar_button_onmouseover(tooltip);\n",
              "            }\n",
              "        };\n",
              "    }\n",
              "\n",
              "    fig.buttons = {};\n",
              "    var buttonGroup = document.createElement('div');\n",
              "    buttonGroup.classList = 'btn-group';\n",
              "    var button;\n",
              "    for (var toolbar_ind in mpl.toolbar_items) {\n",
              "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
              "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
              "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
              "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
              "\n",
              "        if (!name) {\n",
              "            /* Instead of a spacer, we start a new button group. */\n",
              "            if (buttonGroup.hasChildNodes()) {\n",
              "                toolbar.appendChild(buttonGroup);\n",
              "            }\n",
              "            buttonGroup = document.createElement('div');\n",
              "            buttonGroup.classList = 'btn-group';\n",
              "            continue;\n",
              "        }\n",
              "\n",
              "        button = fig.buttons[name] = document.createElement('button');\n",
              "        button.classList = 'btn btn-default';\n",
              "        button.href = '#';\n",
              "        button.title = name;\n",
              "        button.innerHTML = '<i class=\"fa ' + image + ' fa-lg\"></i>';\n",
              "        button.addEventListener('click', on_click_closure(method_name));\n",
              "        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n",
              "        buttonGroup.appendChild(button);\n",
              "    }\n",
              "\n",
              "    if (buttonGroup.hasChildNodes()) {\n",
              "        toolbar.appendChild(buttonGroup);\n",
              "    }\n",
              "\n",
              "    // Add the status bar.\n",
              "    var status_bar = document.createElement('span');\n",
              "    status_bar.classList = 'mpl-message pull-right';\n",
              "    toolbar.appendChild(status_bar);\n",
              "    this.message = status_bar;\n",
              "\n",
              "    // Add the close button to the window.\n",
              "    var buttongrp = document.createElement('div');\n",
              "    buttongrp.classList = 'btn-group inline pull-right';\n",
              "    button = document.createElement('button');\n",
              "    button.classList = 'btn btn-mini btn-primary';\n",
              "    button.href = '#';\n",
              "    button.title = 'Stop Interaction';\n",
              "    button.innerHTML = '<i class=\"fa fa-power-off icon-remove icon-large\"></i>';\n",
              "    button.addEventListener('click', function (_evt) {\n",
              "        fig.handle_close(fig, {});\n",
              "    });\n",
              "    button.addEventListener(\n",
              "        'mouseover',\n",
              "        on_mouseover_closure('Stop Interaction')\n",
              "    );\n",
              "    buttongrp.appendChild(button);\n",
              "    var titlebar = this.root.querySelector('.ui-dialog-titlebar');\n",
              "    titlebar.insertBefore(buttongrp, titlebar.firstChild);\n",
              "};\n",
              "\n",
              "mpl.figure.prototype._remove_fig_handler = function (event) {\n",
              "    var fig = event.data.fig;\n",
              "    if (event.target !== this) {\n",
              "        // Ignore bubbled events from children.\n",
              "        return;\n",
              "    }\n",
              "    fig.close_ws(fig, {});\n",
              "};\n",
              "\n",
              "mpl.figure.prototype._root_extra_style = function (el) {\n",
              "    el.style.boxSizing = 'content-box'; // override notebook setting of border-box.\n",
              "};\n",
              "\n",
              "mpl.figure.prototype._canvas_extra_style = function (el) {\n",
              "    // this is important to make the div 'focusable\n",
              "    el.setAttribute('tabindex', 0);\n",
              "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
              "    // off when our div gets focus\n",
              "\n",
              "    // location in version 3\n",
              "    if (IPython.notebook.keyboard_manager) {\n",
              "        IPython.notebook.keyboard_manager.register_events(el);\n",
              "    } else {\n",
              "        // location in version 2\n",
              "        IPython.keyboard_manager.register_events(el);\n",
              "    }\n",
              "};\n",
              "\n",
              "mpl.figure.prototype._key_event_extra = function (event, _name) {\n",
              "    // Check for shift+enter\n",
              "    if (event.shiftKey && event.which === 13) {\n",
              "        this.canvas_div.blur();\n",
              "        // select the cell after this one\n",
              "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
              "        IPython.notebook.select(index + 1);\n",
              "    }\n",
              "};\n",
              "\n",
              "mpl.figure.prototype.handle_save = function (fig, _msg) {\n",
              "    fig.ondownload(fig, null);\n",
              "};\n",
              "\n",
              "mpl.find_output_cell = function (html_output) {\n",
              "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
              "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
              "    // IPython event is triggered only after the cells have been serialised, which for\n",
              "    // our purposes (turning an active figure into a static one), is too late.\n",
              "    var cells = IPython.notebook.get_cells();\n",
              "    var ncells = cells.length;\n",
              "    for (var i = 0; i < ncells; i++) {\n",
              "        var cell = cells[i];\n",
              "        if (cell.cell_type === 'code') {\n",
              "            for (var j = 0; j < cell.output_area.outputs.length; j++) {\n",
              "                var data = cell.output_area.outputs[j];\n",
              "                if (data.data) {\n",
              "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
              "                    data = data.data;\n",
              "                }\n",
              "                if (data['text/html'] === html_output) {\n",
              "                    return [cell, data, j];\n",
              "                }\n",
              "            }\n",
              "        }\n",
              "    }\n",
              "};\n",
              "\n",
              "// Register the function which deals with the matplotlib target/channel.\n",
              "// The kernel may be null if the page has been refreshed.\n",
              "if (IPython.notebook.kernel !== null) {\n",
              "    IPython.notebook.kernel.comm_manager.register_target(\n",
              "        'matplotlib',\n",
              "        mpl.mpl_figure_comm\n",
              "    );\n",
              "}\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div id='b513bc82-1f0d-4589-98a5-6a3635a5bb4b'></div>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the evaluated model\n",
        "torch.save(model.state_dict(), \"evaluated_model.pth\")\n",
        "\n",
        "# Verify if the file exists\n",
        "import os\n",
        "if os.path.exists(\"evaluated_model.pth\"):\n",
        "    print(\"✅ Model saved successfully!\")\n",
        "else:\n",
        "    print(\"❌ Model save failed!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "GHB_LGd0nNJu",
        "outputId": "cc587a1e-ade7-4575-bca6-92901f1c2283"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Model saved successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"evaluated_model.pth\")  # Change filename if using full model\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "S1qVvST5gEvD",
        "outputId": "e594641a-0a5f-43ba-9acf-1a6c14bb4795"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_1d78650b-39a4-4a12-8078-46fa7b324c25\", \"evaluated_model.pth\", 210409826)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Save model to Drive\n",
        "torch.save(model.state_dict(), \"/content/drive/My Drive/evaluated_model.pth\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "kn_mMG2KgF5j",
        "outputId": "9bb058b6-cc89-4b28-fc69-667e85e3e56a"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "import requests\n",
        "from io import BytesIO\n",
        "\n",
        "# Step 1: Load the trained model\n",
        "model = CNN(targets_size)  # Ensure this matches your defined model class\n",
        "model.load_state_dict(torch.load(\"evaluated_model.pth\", map_location=device))  # Load trained weights\n",
        "model.to(device)\n",
        "model.eval()  # Set model to evaluation mode\n",
        "\n",
        "# Step 2: Define image preprocessing (same as used in training)\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # Resize to match model input\n",
        "    transforms.ToTensor(),  # Convert to tensor\n",
        "])\n",
        "\n",
        "# Step 3: Download the image from URL\n",
        "image_url = \"https://github.com/manthan89-py/Plant-Disease-Detection/blob/main/test_images/Apple_ceder_apple_rust.JPG?raw=true\"  # Replace with actual image URL\n",
        "response = requests.get(image_url)\n",
        "image = Image.open(BytesIO(response.content)).convert(\"RGB\")  # Open and convert to RGB\n",
        "\n",
        "# Step 4: Apply transformations and add batch dimension\n",
        "image = transform(image).unsqueeze(0).to(device)  # Add batch dimension & move to GPU\n",
        "\n",
        "# Step 5: Make a prediction\n",
        "with torch.no_grad():\n",
        "    output = model(image)  # Forward pass\n",
        "    _, predicted_class = torch.max(output, 1)  # Get the predicted class index\n",
        "\n",
        "# Step 6: Display the result\n",
        "class_names = dataset.classes  # Get class names from dataset\n",
        "predicted_label = class_names[predicted_class.item()]  # Convert index to label\n",
        "\n",
        "print(f\"Predicted Class: {predicted_label}\")\n"
      ],
      "metadata": {
        "id": "Ca0gtAQbpMuN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "42f813e5-57ba-4a4e-d8e3-3d978b94cf3a"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Class: Tomato___Bacterial_spot\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "data = pd.read_csv(\"disease_info.csv\", encoding=\"cp1252\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "WKceTXCwro7O",
        "outputId": "29c89140-e5ea-48a6-8220-852d1985533a"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-5e4bc536-fa83-4043-b009-a5af73f17118\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-5e4bc536-fa83-4043-b009-a5af73f17118\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving disease_info.csv to disease_info.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pillow torchvision\n",
        "\n",
        "from PIL import Image\n",
        "import torchvision.transforms.functional as TF"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "gmB0a_9frpkU",
        "outputId": "2646b43a-b75e-4b1b-c708-04db3b5ca67d"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.1.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: torch==2.6.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (4.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchvision) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch==2.6.0->torchvision) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.6.0->torchvision) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_JA5p-XUrzM5"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}